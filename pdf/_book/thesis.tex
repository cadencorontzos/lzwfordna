% This is the Reed College LaTeX thesis template. Most of the work
% for the document class was done by Sam Noble (SN), as well as this
% template. Later comments etc. by Ben Salzberg (BTS). Additional
% restructuring and APA support by Jess Youngberg (JY).
% Your comments and suggestions are more than welcome; please email
% them to cus@reed.edu
%
% See https://www.reed.edu/cis/help/LaTeX/index.html for help. There are a
% great bunch of help pages there, with notes on
% getting started, bibtex, etc. Go there and read it if you're not
% already familiar with LaTeX.
%
% Any line that starts with a percent symbol is a comment.
% They won't show up in the document, and are useful for notes
% to yourself and explaining commands.
% Commenting also removes a line from the document;
% very handy for troubleshooting problems. -BTS

% As far as I know, this follows the requirements laid out in
% the 2002-2003 Senior Handbook. Ask a librarian to check the
% document before binding. -SN

%%
%% Preamble
%%
% \documentclass{<something>} must begin each LaTeX document
\documentclass[12pt,twoside]{reedthesis}
% Packages are extensions to the basic LaTeX functions. Whatever you
% want to typeset, there is probably a package out there for it.
% Chemistry (chemtex), screenplays, you name it.
% Check out CTAN to see: https://www.ctan.org/
%%
\usepackage{graphicx,latexsym}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace}
\usepackage{chemarr} %% Useful for one reaction arrow, useless if you're not a chem major
\usepackage[hyphens]{url}
% Added by CII
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage{float}
\floatplacement{figure}{H}
% Thanks, @Xyv
\usepackage{calc}
% End of CII addition
\usepackage{rotating}

% Next line commented out by CII
%%% \usepackage{natbib}
% Comment out the natbib line above and uncomment the following two lines to use the new
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the
% bibliography is included.
%\usepackage{biblatex-chicago}
%\bibliography{thesis}


% Added by CII (Thanks, Hadley!)
% Use ref for internal links
\renewcommand{\hyperref}[2][???]{\autoref{#1}}
\def\chapterautorefname{Chapter}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}
% End of CII addition

% Added by CII
\usepackage{caption}
\captionsetup{width=5in}
% End of CII addition

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino

% Syntax highlighting #22
  \usepackage{color}
  \usepackage{fancyvrb}
  \newcommand{\VerbBar}{|}
  \newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
  % Add ',fontsize=\small' for more characters per line
  \usepackage{framed}
  \definecolor{shadecolor}{RGB}{248,248,248}
  \newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
  \newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
  \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
  \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\BuiltInTok}[1]{#1}
  \newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
  \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
  \newcommand{\ExtensionTok}[1]{#1}
  \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ImportTok}[1]{#1}
  \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\NormalTok}[1]{#1}
  \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
  \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
  \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\RegionMarkerTok}[1]{#1}
  \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% To pass between YAML and LaTeX the dollar signs are added by CII
\title{Optimizing Lempel Ziv Welch for DNA Compression}
\author{Caden Corontzos}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{May 2023}
\division{Mathematics and Natural Sciences}
\advisor{Eitan Frachtenberg}
\institution{Reed College}
\degree{Bachelor of Arts}
%If you have two advisors for some reason, you can use the following
% Uncommented out by CII
% End of CII addition

%%% Remember to use the correct department!
\department{Computer Science}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
%\thedivisionof{The Established Interdisciplinary Committee for}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
%\approvedforthe{Committee}

% Added by CII
%%% Copied from knitr
%% maxwidth is the original width if it's less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

% From {rticles}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
% for Pandoc 2.8 to 2.10.1
\newenvironment{cslreferences}%
  {}%
  {\par}
% For Pandoc 2.11+
% As noted by @mirh [2] is needed instead of [3] for 2.12
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc} % for calculating minipage widths
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\renewcommand{\contentsname}{Table of Contents}
% End of CII addition

\setlength{\parskip}{0pt}

% Added by CII

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\Acknowledgements{
I want to thank a few people.
}

\Dedication{
You can have a dedication here if you wish.
}

\Preface{
This is an example of a thesis setup to use the reed thesis document class
(for LaTeX) and the R bookdown package, in general.
}

\Abstract{
The Lempel Ziv Welch compression algorithm is a lossless data compression algorithm used for numerous applications, including the Unix file compression utility \texttt{compress} and the GIF image format. Storing, reading, and transferring enormous amounts of data is often an issue in the biological field, especially when concerning DNA. This thesis explores the application of Lempel Ziv Welch to the compression of DNA. A variety of different optimization of the original LZW algorithm are explore included palatalizing, multiple dictionaries, and some other cool thing here broh.
}

	\usepackage{setspace}\onehalfspacing
	\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
% End of CII addition
%%
%% End Preamble
%%
%
\begin{document}

% Everything below added by CII
  \maketitle

\frontmatter % this stuff will be roman-numbered
\pagestyle{empty} % this removes page numbers from the frontmatter
  \begin{acknowledgements}
    I want to thank a few people.
  \end{acknowledgements}
  \begin{preface}
    This is an example of a thesis setup to use the reed thesis document class
    (for LaTeX) and the R bookdown package, in general.
  \end{preface}
\chapter*{List of Abbreviations}
\begin{table}[h]
    \centering
    \begin{tabular}{ll}
                \textbf{LZW} & Lempel Ziv Welch \\
            \end{tabular}
\end{table}
  \hypersetup{linkcolor=black}
  \setcounter{secnumdepth}{2}
  \setcounter{tocdepth}{2}
  \tableofcontents

  \listoftables

  \listoffigures
  \begin{abstract}
    The Lempel Ziv Welch compression algorithm is a lossless data compression algorithm used for numerous applications, including the Unix file compression utility \texttt{compress} and the GIF image format. Storing, reading, and transferring enormous amounts of data is often an issue in the biological field, especially when concerning DNA. This thesis explores the application of Lempel Ziv Welch to the compression of DNA. A variety of different optimization of the original LZW algorithm are explore included palatalizing, multiple dictionaries, and some other cool thing here broh.
  \end{abstract}
  \begin{dedication}
    You can have a dedication here if you wish.
  \end{dedication}
\mainmatter % here the regular arabic numbering starts
\pagestyle{fancyplain} % turns page numbering back on

\hypertarget{introduction}{%
\chapter*{Introduction}\label{introduction}}
\addcontentsline{toc}{chapter}{Introduction}

When dealing with DNA, it

\hypertarget{backround-and-motivations}{%
\chapter{Backround and Motivations}\label{backround-and-motivations}}

This thesis deals with some high level topics and uses language specific to compression research. This chapter tries to give brief summaries and examples of the relevant topics to be discussed so readers of all experience levels can put our results into context.

\hypertarget{what-is-information}{%
\section{What is information?}\label{what-is-information}}

Suppose you had an idea that you wanted to share with another person. Humans have many ways to communicate information; you could send a text message, you could tell them with words, you could tell them with sign language. But regardless of the medium, you have some idea that you want to get across. Does it matter if the other person gets your message exactly? Or can it be part of the message? If someone asks you ``Where library'', despite the lack of prepositions you still understand what they mean. So did that person convey any less information than a person who asks ``Where is the library?''
Clearly, information is fundamental to how humans interact and how they understand the world, but defining it proves difficult. For our purposes, let us assume that information is something that can be interpreted to glean information that you didn't know before.

\hypertarget{compression-a-history}{%
\section{Compression: A history}\label{compression-a-history}}

\hypertarget{compression-metrics}{%
\section{Compression Metrics}\label{compression-metrics}}

\hypertarget{compression-ratio}{%
\subsection{Compression Ratio}\label{compression-ratio}}

Compression Ratio is the measure of size reduction achieved by a compression algorithm. It is typically expressd as a ratio of the size of the uncompressed data (\(OS\)) to the size of the compressed data (\{CS\}).

\[CR = \frac{OS}{CS}\]

So a higher compression ratio means a more effective compression algorithm, and means that we were able to store more data in less space, allowing for easier storage and transfer.

\hypertarget{runtime}{%
\subsection{Runtime}\label{runtime}}

The runtime is also an important part of evaluating the effectiveness of a compression algorithm. If you have the option of two compression algorithms, one with a compression ratio of 2.0, and another with a compression ratio of 2.15 but takes twice as long as the other, you may opt for a lower compression ratio to save time.

\hypertarget{memory-usage}{%
\subsection{Memory Usage}\label{memory-usage}}

Memory usage is closely tied with runtime when it comes to compression algorithms. Memory generally refers to information that programs track as they are running on a computer. So do reduce our runtime and make a more effective compression algorithm, we want to be saving only the most important data that our algoritm needs in order to reduce our memory usage.

\hypertarget{lossless-vs.-lossy-compression}{%
\section{Lossless vs.~Lossy Compression}\label{lossless-vs.-lossy-compression}}

\hypertarget{lossy}{%
\subsection{Lossy}\label{lossy}}

Lossy compression is based on the idea that not all information is vital. For instance, when saving a picture on your computer, your computer may save it in the .jpeg format to save space. Jpegs lose some of the information in the original picture and produce an overall lower quality picture, but the general information in the picture is preserved. Another example

\hypertarget{lossless}{%
\subsection{Lossless}\label{lossless}}

Lossless compression is the compression of data with the goal of preserving all the information in the data. As a result, lossless compression algorithms usually don't compress as well as their lossy counterparts. Examples of lossless compression algoritms are Huffman Encoding and Lempel Ziv Welch, which is the focus of this thesis.

\hypertarget{examples-of-compression-algorithms}{%
\section{Examples of Compression Algorithms}\label{examples-of-compression-algorithms}}

\hypertarget{run-length-encoding}{%
\subsection{Run Length Encoding}\label{run-length-encoding}}

Run Length Encoding (RLE) is on of the simplest and most intuitive forms of compression. We can take advantage of redundant runs of characters in a sequence by just giving the number of times each character appears.
Suppose you want to send the following message

AAGCTTTTTTTTGGGGGCCCT

Even if this message did mean something, we can get the information across without repeating ourselves. When writing a grocery list, you don't write ``egg egg egg egg'', you say ``4 eggs''. RLE uses this same strategdy.

2A1G1C8T5G3C1T

We could compress this even further if we omit the 1 on characters that only appear once.

\hypertarget{huffman}{%
\subsection{Huffman}\label{huffman}}

Huffman Encoding is a strategdy that assigns variable length code to certain symbols in the data. The goal is to assign short codes to frequently appearing symbols and longer codes to less frequent symbols.

Put example here

\hypertarget{arithmetic}{%
\subsection{Arithmetic}\label{arithmetic}}

Arithmetic encoding is another lossless compression algorithm that uses probability to asssign codes to symbols in the message. Unlike Huffman, arithmetic enoding assins a single code to the whole message, rather than seperate codes for each symbol.

Here is a simple example. Say we want to encode a string of characters ``ACCGGGGTTT''. The probability of each symbol in the message are
\begin{itemize}
\tightlist
\item
  P(A) = 1/10
\item
  P(C) = 2/10
\item
  P(G) = 4/10
\item
  P(T) = 3/10
\end{itemize}
We want to represent the message as a fractional number between 0 and 1. We will divide the interval {[}0,1{]} into sub intervals using the probabilities of each character in the message. That way, each symbol is reprsented by the sub-interval that corresponds to its probablity.

Arithmetic encoding can have a better compression ratio that Huffman in some cases, but the computation time is often not worth the payoff.

\hypertarget{lempel-ziv-welch}{%
\subsection{Lempel Ziv Welch}\label{lempel-ziv-welch}}

Lempel Ziv Welch is another lossless compression algorithm. When compressing, LZW builds a dictionary of codewords, where codewords represent strings previously seen in the message. As it compresses the message, the dictionary grows. The compression algorithm leaves behind the codewords and some of the original characters, allowing the decompression algorithm to build up the same dictionary as it decompresses the message.

Here is a simple example. We may be sending messages with the characters \{`A', `C', `T', `G'\}, so I will start with those in my dictionary. Say we want to send the message

``AAGGAATCC''

When we compress, we start at the beginning of the message and scan through.

\hypertarget{optimizing-lzw-approach}{%
\chapter{Optimizing LZW: Approach}\label{optimizing-lzw-approach}}

To restate the goal of this thesis, we seek to optimize LZW for use in compression of DNA. I chose to write in C++.

\hypertarget{supporting-research}{%
\section{Supporting Research}\label{supporting-research}}

There has been several attempts to optimize LZW by computer science researchers.

There has also been attempts to generally improve performance of LZW

\hypertarget{corpora}{%
\section{Corpora}\label{corpora}}

Most compression papers make use of a Corpus, which is a collection of files to run a compression algorithm on in order to evaluate performance and to compare different algorithms to one another.

In the world of DNA compression, there are several academic papers on the subject. One of the first and most popular of the papers was published in 1994, and the selection of DNA sequences used in the paper have become an informal corpus for the subject of DNA compression (Grumbach \& Tahi, 1994).
\begin{longtable}[]{@{}cc@{}}
\toprule()
Name & Size.bytes. \\
\midrule()
\endhead
chmpxx & 121024 \\
chntxx & 155844 \\
hehcmv & 229354 \\
humdyst & 38770 \\
humghcs & 66495 \\
humhbb & 73308 \\
humhdab & 58864 \\
humprtb & 56737 \\
mpomtcg & 186609 \\
mtpacga & 100314 \\
vaccg & 191737 \\
\bottomrule()
\end{longtable}
Another, newer paper aimed to create a corpus specifically for compressing DNA (Pratas \& Pinho, 2018). They put together a corpus of DNA sequences for this purpose, as summarized below. Since the papers publishing, it has been cited by several DNA compression papers.
\begin{longtable}[]{@{}cc@{}}
\toprule()
Name & Size.bytes. \\
\midrule()
\endhead
AeCa & 1591049 \\
AgPh & 43970 \\
BuEb & 18940 \\
DaRe & 62565020 \\
DrMe & 32181429 \\
EnIn & 26403087 \\
EsCo & 4641652 \\
GaGa & 148532294 \\
HaHi & 3890005 \\
HePy & 1667825 \\
HoSa & 189752667 \\
OrSa & 43262523 \\
PlFa & 8986712 \\
ScPo & 10652155 \\
YeMi & 73689 \\
\bottomrule()
\end{longtable}
This particular dataset is publicly available at this \href{https://tinyurl.com/DNAcorpus}{link}.

\hypertarget{evaluating-performance}{%
\section{Evaluating Performance}\label{evaluating-performance}}

Evaluating performance of a program is difficult. There is a notion of theoretical run time, but on an actual computer there are many processes running in the background, so it can be hard to get a consistent reading on performance.

To attempt to counteract this, we ran the function on the same file

\hypertarget{a-starting-point}{%
\section{A Starting Point}\label{a-starting-point}}

As a starting point, we thought it was best to get a working implementation of LZW in C++ on regular text files, optimize it as much as we could, and then try variations from there, optimizing it for DNA.

\hypertarget{growing-codewords-and-bit-output}{%
\subsection{Growing Codewords and Bit Output}\label{growing-codewords-and-bit-output}}

When reading files on the computer, most characters are stored as bytes, which is made up of 8 bits. For instance \texttt{01000001} stands for the letter `A' in ASCII encoding. Numbers are more simple to display, so \texttt{00000001} is 1, \texttt{00000010} is 2, and so on.

But if we are translating numbers to binary, we don't need all of the bits in a byte. In binary, \texttt{1} is the same as \texttt{01} is the same as \texttt{00000000000001}. So when we are outputting codewords for LZW, we don't necessarily need to output a whole byte. We can have growing codewords.

As the number of codewords grows, the number of bits needed to represent it also grows. So if we are on codeword 8, we need 4 bits since 8 is \texttt{1000}. As our dictionary grows, we can grow the number of bits needed to display a codeword and save a lot of space in our compressed document.

So we needed a method of outputting bits one by one, and reading in bits one by one. This is not something that is supported in C++ on its own. We were able to create this functionality by defining a class.
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// BitInput: Read a single bit at a time from an input stream.}
\CommentTok{// Before reading any bits, ensure your input stream still has valid inputs.}
\KeywordTok{class}\NormalTok{ BitInput }\OperatorTok{\{}
 \KeywordTok{public}\OperatorTok{:}
  \CommentTok{// Construct with an input stream}
\NormalTok{  BitInput}\OperatorTok{(}\AttributeTok{const} \DataTypeTok{char}\OperatorTok{*}\NormalTok{ input}\OperatorTok{);}

\NormalTok{  BitInput}\OperatorTok{(}\AttributeTok{const}\NormalTok{ BitInput}\OperatorTok{\&)} \OperatorTok{=} \ControlFlowTok{default}\OperatorTok{;}
\NormalTok{  BitInput}\OperatorTok{(}\NormalTok{BitInput}\OperatorTok{\&\&)} \OperatorTok{=} \ControlFlowTok{default}\OperatorTok{;}

  \CommentTok{// bool eof();}
  \CommentTok{// Read a single bit (or trailing zero)}
  \CommentTok{// Allowed to crash or throw an exception if called past end{-}of{-}file.}
  \DataTypeTok{bool}\NormalTok{ input\_bit}\OperatorTok{();}

  \DataTypeTok{int}\NormalTok{ read\_n\_bits}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{);}
\OperatorTok{\}}

\CommentTok{// BitOutput: Write a single bit at a time to an output stream}
\CommentTok{// Make sure all bits are written out by the time the destructor is done.}
\KeywordTok{class}\NormalTok{ BitOutput }\OperatorTok{\{}
 \KeywordTok{public}\OperatorTok{:}
  \CommentTok{// Construct with an input stream}
\NormalTok{  BitOutput}\OperatorTok{(}\BuiltInTok{std::}\NormalTok{ostream}\OperatorTok{\&}\NormalTok{ os}\OperatorTok{);}

  \CommentTok{// Flushes out any remaining output bits and trailing zeros, if any:}
  \OperatorTok{\textasciitilde{}}\NormalTok{BitOutput}\OperatorTok{();}

\NormalTok{  BitOutput}\OperatorTok{(}\AttributeTok{const}\NormalTok{ BitOutput}\OperatorTok{\&)} \OperatorTok{=} \ControlFlowTok{default}\OperatorTok{;}
\NormalTok{  BitOutput}\OperatorTok{(}\NormalTok{BitOutput}\OperatorTok{\&\&)} \OperatorTok{=} \ControlFlowTok{default}\OperatorTok{;}

  \CommentTok{// Output a single bit (buffered)}
  \DataTypeTok{void}\NormalTok{ output\_bit}\OperatorTok{(}\DataTypeTok{bool}\NormalTok{ bit}\OperatorTok{);}

  \DataTypeTok{void}\NormalTok{ output\_n\_bits}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ bits}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
So when we are encoding and need to output a codeword, we can \texttt{output\_n\_bits}, where \texttt{n} is the number of bits needed to display our greatest codeword. When decoding, we can just \texttt{read\_n\_bits}.

\hypertarget{getting-eof-to-work}{%
\subsection{Getting EOF to work}\label{getting-eof-to-work}}

One of the very early issues with the implementation was how to denote the end of a file. The early implementation would work for some files, but for others the very last part of the file would be lost after encoding and then decoding.

In theoretical implementations of LZW, computer scientists tend to denote the end of a message with a special character, one that isn't seen anywhere else in the file. In this initial implementation, that wasn't possible because we wanted to be able to compress any file with any characters.

The solution was to reserve a codeword to mark the end of the file. So we start with a starting dictionary containing all ASCII characters.
\begin{Shaded}
\begin{Highlighting}[]
    \BuiltInTok{std::}\NormalTok{unordered\_map}\OperatorTok{\textless{}}\BuiltInTok{std::}\NormalTok{string}\OperatorTok{,} \DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ dictionary}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{256}\OperatorTok{;} \OperatorTok{++}\NormalTok{i}\OperatorTok{)\{}
        \BuiltInTok{std::}\NormalTok{string}\OperatorTok{ }\NormalTok{str1}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DataTypeTok{char}\OperatorTok{(}\NormalTok{i}\OperatorTok{));}
\NormalTok{        dictionary}\OperatorTok{[}\NormalTok{str1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
Then use the code 256 to denote the end of file. So the algorithm goes along reading a file. It builds up a current string character by character, adding the character to the string and checking if it has seen that sequence before. Once it find the end of file, we stop and output the EOF codeword.

The problem was, what about what is left over? Suppose we are reading a file, and the file ends with ``ACCT''. If ``A'' is in the dictionary, we see if ``AC'' is in the dictionary, and so on. This leaves us with three possible cases when we reached the end of the file
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ``ACC'' was in the dictionary but ``ACCT'' was not. This means we can output the codeword for ``ACC'', follow it by the character ``T'', and we are done. This is the ideal scenario, because nothing is left over when we output the EOF codeword
\item
  ``ACCT'' was in the dictionary: This means we have one more codeword to output, but since we reached the end of the file, we never got to output it.
\item
  ``AC'' was in the dictionary, but ``ACC'' was not: in this case, we would output the codeword for ``AC'' output the character ``C'', and then start looping again starting at ``T''. But we reach the end of the file, so we output EOF before outputting T.
\end{enumerate}
We solved this issue by adding 2 extra bits after the EOF codeword. These bits denote the case that occurred
\begin{Shaded}
\begin{Highlighting}[]
    \CommentTok{// after we\textquotesingle{}ve encoded, we either have }
    \CommentTok{// no current block (case 0)}
    \CommentTok{// we have a current block that is a single character (case 1)}
    \CommentTok{// otherwise we have a current block \textgreater{} 1 byte (default)}
    \ControlFlowTok{switch} \OperatorTok{(}\NormalTok{currentBlock}\OperatorTok{.}\NormalTok{length}\OperatorTok{())\{}
    \ControlFlowTok{case} \DecValTok{0}\OperatorTok{:}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_bit}\OperatorTok{(}\KeywordTok{false}\OperatorTok{);}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_bit}\OperatorTok{(}\KeywordTok{false}\OperatorTok{);}
        \ControlFlowTok{break}\OperatorTok{;}
    \ControlFlowTok{case} \DecValTok{1}\OperatorTok{:}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_bit}\OperatorTok{(}\KeywordTok{false}\OperatorTok{);}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_bit}\OperatorTok{(}\KeywordTok{true}\OperatorTok{);}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_n\_bits}\OperatorTok{((}\DataTypeTok{int}\OperatorTok{)}\NormalTok{ currentBlock}\OperatorTok{[}\DecValTok{0}\OperatorTok{],}\NormalTok{ CHAR\_BIT}\OperatorTok{);}
        \ControlFlowTok{break}\OperatorTok{;}
    \ControlFlowTok{default}\OperatorTok{:}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_bit}\OperatorTok{(}\KeywordTok{true}\OperatorTok{);}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_bit}\OperatorTok{(}\KeywordTok{true}\OperatorTok{);}

        \DataTypeTok{int}\NormalTok{ code }\OperatorTok{=}\NormalTok{ dictionary}\OperatorTok{[}\NormalTok{currentBlock}\OperatorTok{];}
\NormalTok{        bit\_output}\OperatorTok{.}\NormalTok{output\_n\_bits}\OperatorTok{(}\NormalTok{code}\OperatorTok{,}\NormalTok{ codeword\_size}\OperatorTok{);}
        \ControlFlowTok{break}\OperatorTok{;}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
So when the decoded is reading and encounters the EOF codeword, it can look at the next two bits to see if anything is left over.

At this point, there was a working implementation that was able to compress and decompress files. Here is the performance of this version on the two copora.
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus1/humprtb & 56737 & 21902 & 2.590 & 7 & 2\\
DNACorpus1/humdyst & 38770 & 15300 & 2.534 & 5 & 1\\
DNACorpus1/vaccg & 191737 & 70067 & 2.736 & 18 & 7\\
DNACorpus1/hehcmv & 229354 & 85526 & 2.682 & 23 & 9\\
DNACorpus1/mpomtcg & 186609 & 70254 & 2.656 & 18 & 7\\
\addlinespace
DNACorpus1/humhdab & 58864 & 22699 & 2.593 & 8 & 2\\
DNACorpus1/chmpxx & 121024 & 43516 & 2.781 & 13 & 4\\
DNACorpus1/mtpacga & 100314 & 36862 & 2.721 & 11 & 4\\
DNACorpus1/chntxx & 155844 & 58336 & 2.671 & 16 & 6\\
DNACorpus1/humghcs & 66495 & 25552 & 2.602 & 7 & 2\\
\addlinespace
DNACorpus1/humhbb & 73308 & 28134 & 2.606 & 8 & 3\\
\bottomrule
\end{tabular}}
\end{table}
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus2/YeMi & 73689 & 27235 & 2.706 & 9 & 3\\
DNACorpus2/DaRe & 62565020 & 19586457 & 3.194 & 15034 & 1898\\
DNACorpus2/EnIn & 26403087 & 8609993 & 3.067 & 5427 & 781\\
DNACorpus2/HePy & 1667825 & 566972 & 2.942 & 145 & 40\\
DNACorpus2/OrSa & 43262523 & 14148071 & 3.058 & 9790 & 1350\\
\addlinespace
DNACorpus2/EsCo & 4641652 & 1593404 & 2.913 & 569 & 121\\
DNACorpus2/GaGa & 148532294 & 46851765 & 3.170 & 40810 & 4773\\
DNACorpus2/ScPo & 10652155 & 3590856 & 2.966 & 1761 & 295\\
DNACorpus2/HaHi & 3890005 & 1306708 & 2.977 & 445 & 97\\
DNACorpus2/HoSa & 189752667 & 57200209 & 3.317 & 53818 & 5913\\
\addlinespace
DNACorpus2/AeCa & 1591049 & 556535 & 2.859 & 141 & 40\\
DNACorpus2/DrMe & 32181429 & 10619042 & 3.031 & 7190 & 1015\\
DNACorpus2/BuEb & 18940 & 7893 & 2.400 & 2 & 0\\
DNACorpus2/PlFa & 8986712 & 2895744 & 3.103 & 1367 & 238\\
DNACorpus2/AgPh & 43970 & 17442 & 2.521 & 6 & 2\\
\bottomrule
\end{tabular}}
\end{table}
\hypertarget{using-constants}{%
\subsection{Using Constants}\label{using-constants}}

The early version of the code was not clean. There were hard coded variables, unspecified integer types, and generally messy naming conventions that made the code difficult to read and debug.

The next major step in the code was to start using constants for everything, including
\begin{itemize}
\tightlist
\item
  \texttt{STARTING\_CODEWORD}: What codeword we should start at
\item
  \texttt{EOF\_CODEWORD}: What we should output when we reach end of file
\item
  \texttt{STARTING\_DICT\_SIZE}: At this stage, we had a starting dict size of 256 to hold all possible bytes, but later we will specialize for DNA
\end{itemize}
It also made sense to start using a specific type for codewords. At this stage, we opted for a 32 bit integer.

There are several tools at a developers disposal when looking to debug and optimize code. One tool used for this thesis was \texttt{callgrind} which is a tool of \texttt{valgrind} a profiling tool. Profiling tools are used to look at how your code works, where the bottlenecks are, and what can be changed/improved for the performance of your code.

Callgrind in particular is a profiling tool which associates assembly instructions to lines of code, indicating to the programmer which lines take a lot of instructions and which take less. For those unfamiliar, assembly instructions are what code is turned into so that it can be ran on your computer's processor. In general, more instructions means that code takes longer to run.

The callgrind output drew attention to one particular part of the code. A C++ \texttt{unordered\_map} uses iterators, basically pointers into the dictionary. If an entry is not present in the dictionary, the \texttt{find()} function will return a iterator to the end of the dictionary.

The check for this in our algorithm looked like this.
\begin{Shaded}
\begin{Highlighting}[]
        \CommentTok{// if we\textquotesingle{}ve already seen the sequence, keep going}
        \CommentTok{// }\AlertTok{TODO}\CommentTok{: use cend() and save this iterator}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dictionary}\OperatorTok{.}\NormalTok{find}\OperatorTok{(}\NormalTok{currentBlock }\OperatorTok{+}\NormalTok{ next\_character}\OperatorTok{)} \OperatorTok{!=}\NormalTok{ dictionary}\OperatorTok{.}\NormalTok{end}\OperatorTok{())\{}
\NormalTok{            currentBlock }\OperatorTok{=}\NormalTok{ currentBlock }\OperatorTok{+}\NormalTok{ next\_character}\OperatorTok{;}
        \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
Here is the callgrind output for that line.
\begin{verbatim}
105,030,135 ( 0.18%)          if (dictionary.find(currentBlock + next_character) != dictionary.end()){
13,537,450,317 (22.83%)  => /usr/include/c++/9/bits/basic_string.h:std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > std::operator+<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char) (3,890,005x)
11,653,779,430 (19.65%)  => /usr/include/c++/9/bits/unordered_map.h:std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (3,890,005x)
2,108,383,120 ( 3.56%)  => /usr/include/c++/9/bits/basic_string.h:std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string() (3,890,005x)
956,941,242 ( 1.61%)  => /usr/include/c++/9/bits/unordered_map.h:std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long> > >::end() (3,890,005x)
241,180,314 ( 0.41%)  => /usr/include/c++/9/bits/hashtable_policy.h:bool std::__detail::operator!=<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long>, true>(std::__detail::_Node_iterator_base<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long>, true> const&, std::__detail::_Node_iterator_base<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long>, true> const&) (3,890,005x)
\end{verbatim}
As shown, this line is taking a significant amount of instructions, and it needs to pull the end() of the dictionary each time it is ran. If we use cend() instead and save that iterator in a variable called end, we can save a significant amount of instructions.
\begin{verbatim}
89,470,115 ( 0.61%)          if (dictionary.find(currentBlock + next_character) != end ){
3,353,009,053 (22.78%)  => /usr/include/c++/9/bits/basic_string.h:std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > std::operator+<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char) (3,890,005x)
2,833,786,025 (19.26%)  => /usr/include/c++/9/bits/unordered_map.h:std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (3,890,005x)
420,120,704 ( 2.85%)  => /usr/include/c++/9/bits/basic_string.h:std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string() (3,890,005x)
50,570,065 ( 0.34%)  => /usr/include/c++/9/bits/hashtable_policy.h:bool std::__detail::operator!=<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long>, true>(std::__detail::_Node_iterator_base<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long>, true> const&, std::__detail::_Node_iterator_base<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long>, true> const&) (3,890,005x)
\end{verbatim}
Of course, there are several issues with this method. It is difficult to associate instructions with a single line of code. Some lines are interdependent, and assembly often behaves differently than the code that produces it. Another thing is that compliers are very advanced, and sometimes small optimizations like this are done by the compiler automatically.

Despite these issues, this change was still worth making, if not to save time then for sake of clarity and readability of the code. Also, despite the inaccuracy of callgrind, like many profiling tools, its job is not necessarily to provide exact measurements of code performance, but to give indications to trouble spots which can be improved.

Here are the runs after this optimization.
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus1/humprtb & 56737 & 21902 & 2.590 & 7 & 2\\
DNACorpus1/humdyst & 38770 & 15300 & 2.534 & 5 & 1\\
DNACorpus1/vaccg & 191737 & 70067 & 2.736 & 19 & 7\\
DNACorpus1/hehcmv & 229354 & 85526 & 2.682 & 23 & 9\\
DNACorpus1/mpomtcg & 186609 & 70254 & 2.656 & 19 & 7\\
\addlinespace
DNACorpus1/humhdab & 58864 & 22699 & 2.593 & 7 & 2\\
DNACorpus1/chmpxx & 121024 & 43516 & 2.781 & 12 & 4\\
DNACorpus1/mtpacga & 100314 & 36862 & 2.721 & 11 & 4\\
DNACorpus1/chntxx & 155844 & 58336 & 2.671 & 16 & 6\\
DNACorpus1/humghcs & 66495 & 25552 & 2.602 & 9 & 2\\
\addlinespace
DNACorpus1/humhbb & 73308 & 28134 & 2.606 & 10 & 3\\
\bottomrule
\end{tabular}}
\end{table}
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus2/YeMi & 73689 & 27235 & 2.706 & 9 & 3\\
DNACorpus2/DaRe & 62565020 & 19586457 & 3.194 & 14940 & 1880\\
DNACorpus2/EnIn & 26403087 & 8609993 & 3.067 & 5401 & 769\\
DNACorpus2/HePy & 1667825 & 566972 & 2.942 & 144 & 40\\
DNACorpus2/OrSa & 43262523 & 14148071 & 3.058 & 9782 & 1344\\
\addlinespace
DNACorpus2/EsCo & 4641652 & 1593404 & 2.913 & 569 & 118\\
DNACorpus2/GaGa & 148532294 & 46851765 & 3.170 & 41060 & 4787\\
DNACorpus2/ScPo & 10652155 & 3590856 & 2.966 & 1738 & 292\\
DNACorpus2/HaHi & 3890005 & 1306708 & 2.977 & 444 & 97\\
DNACorpus2/HoSa & 189752667 & 57200209 & 3.317 & 53774 & 5854\\
\addlinespace
DNACorpus2/AeCa & 1591049 & 556535 & 2.859 & 139 & 40\\
DNACorpus2/DrMe & 32181429 & 10619042 & 3.031 & 7188 & 1009\\
DNACorpus2/BuEb & 18940 & 7893 & 2.400 & 2 & 1\\
DNACorpus2/PlFa & 8986712 & 2895744 & 3.103 & 1352 & 237\\
DNACorpus2/AgPh & 43970 & 17442 & 2.521 & 5 & 2\\
\bottomrule
\end{tabular}}
\end{table}
\hypertarget{extraneous-string-concatenations}{%
\subsection{Extraneous String Concatenations}\label{extraneous-string-concatenations}}

The LZW algorithm is build on iteration: we go through each character, adding it to our current block. If we've seen that current block before, we keep going. If not, we add that block to the dictionary and start over.

Another thing that I noticed from the callgrind output was that a lot of time/instructions are being spent on string concatenation. Every time we have already seen a sequence, we have to concatenate a character. I also noticed that I was doing this concatenation multiple times without needing to.
\begin{Shaded}
\begin{Highlighting}[]
        \CommentTok{// we concatenate the strings here}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dictionary}\OperatorTok{.}\NormalTok{find}\OperatorTok{(}\NormalTok{currentBlock }\OperatorTok{+}\NormalTok{ next\_character}\OperatorTok{)} \OperatorTok{!=}\NormalTok{ end }\OperatorTok{)\{}
            \CommentTok{// and here}
\NormalTok{            currentBlock }\OperatorTok{=}\NormalTok{ currentBlock }\OperatorTok{+}\NormalTok{ next\_character}\OperatorTok{;}
        \OperatorTok{\}}
        \ControlFlowTok{else}\OperatorTok{\{}

            \CommentTok{// other code here ommitted}


            \CommentTok{// and here! }
\NormalTok{            dictionary}\OperatorTok{[}\NormalTok{currentBlock }\OperatorTok{+}\NormalTok{ next\_character}\OperatorTok{]} \OperatorTok{=}\NormalTok{ codeword}\OperatorTok{;}
        \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}
If I just concatenate them and save the output into a new string, that will save me from doing the concatenation 2 more times.
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus1/humprtb & 56737 & 21902 & 2.590 & 6 & 2\\
DNACorpus1/humdyst & 38770 & 15300 & 2.534 & 4 & 1\\
DNACorpus1/vaccg & 191737 & 70067 & 2.736 & 16 & 7\\
DNACorpus1/hehcmv & 229354 & 85526 & 2.682 & 20 & 9\\
DNACorpus1/mpomtcg & 186609 & 70254 & 2.656 & 17 & 7\\
\addlinespace
DNACorpus1/humhdab & 58864 & 22699 & 2.593 & 6 & 2\\
DNACorpus1/chmpxx & 121024 & 43516 & 2.781 & 12 & 4\\
DNACorpus1/mtpacga & 100314 & 36862 & 2.721 & 10 & 4\\
DNACorpus1/chntxx & 155844 & 58336 & 2.671 & 15 & 6\\
DNACorpus1/humghcs & 66495 & 25552 & 2.602 & 8 & 2\\
\addlinespace
DNACorpus1/humhbb & 73308 & 28134 & 2.606 & 8 & 3\\
\bottomrule
\end{tabular}}
\end{table}
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus2/YeMi & 73689 & 27235 & 2.706 & 8 & 3\\
DNACorpus2/DaRe & 62565020 & 19586457 & 3.194 & 14450 & 1876\\
DNACorpus2/EnIn & 26403087 & 8609993 & 3.067 & 5186 & 762\\
DNACorpus2/HePy & 1667825 & 566972 & 2.942 & 129 & 38\\
DNACorpus2/OrSa & 43262523 & 14148071 & 3.058 & 9392 & 1329\\
\addlinespace
DNACorpus2/EsCo & 4641652 & 1593404 & 2.913 & 525 & 119\\
DNACorpus2/GaGa & 148532294 & 46851765 & 3.170 & 39700 & 4741\\
DNACorpus2/ScPo & 10652155 & 3590856 & 2.966 & 1640 & 289\\
DNACorpus2/HaHi & 3890005 & 1306708 & 2.977 & 410 & 96\\
DNACorpus2/HoSa & 189752667 & 57200209 & 3.317 & 51901 & 5848\\
\addlinespace
DNACorpus2/AeCa & 1591049 & 556535 & 2.859 & 126 & 40\\
DNACorpus2/DrMe & 32181429 & 10619042 & 3.031 & 6861 & 1001\\
DNACorpus2/BuEb & 18940 & 7893 & 2.400 & 2 & 0\\
DNACorpus2/PlFa & 8986712 & 2895744 & 3.103 & 1258 & 234\\
DNACorpus2/AgPh & 43970 & 17442 & 2.521 & 5 & 2\\
\bottomrule
\end{tabular}}
\end{table}
\hypertarget{dictionary-accesses}{%
\subsection{Dictionary Accesses}\label{dictionary-accesses}}
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus1/humprtb & 56737 & 21902 & 2.590 & 5 & 2\\
DNACorpus1/humdyst & 38770 & 15300 & 2.534 & 4 & 1\\
DNACorpus1/vaccg & 191737 & 70067 & 2.736 & 17 & 7\\
DNACorpus1/hehcmv & 229354 & 85526 & 2.682 & 20 & 9\\
DNACorpus1/mpomtcg & 186609 & 70254 & 2.656 & 17 & 7\\
\addlinespace
DNACorpus1/humhdab & 58864 & 22699 & 2.593 & 6 & 2\\
DNACorpus1/chmpxx & 121024 & 43516 & 2.781 & 11 & 4\\
DNACorpus1/mtpacga & 100314 & 36862 & 2.721 & 11 & 3\\
DNACorpus1/chntxx & 155844 & 58336 & 2.671 & 16 & 6\\
DNACorpus1/humghcs & 66495 & 25552 & 2.602 & 7 & 2\\
\addlinespace
DNACorpus1/humhbb & 73308 & 28134 & 2.606 & 8 & 3\\
\bottomrule
\end{tabular}}
\end{table}
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus2/YeMi & 73689 & 27235 & 2.706 & 7 & 3\\
DNACorpus2/DaRe & 62565020 & 19586457 & 3.194 & 14146 & 1869\\
DNACorpus2/EnIn & 26403087 & 8609993 & 3.067 & 5087 & 758\\
DNACorpus2/HePy & 1667825 & 566972 & 2.942 & 127 & 39\\
DNACorpus2/OrSa & 43262523 & 14148071 & 3.058 & 9278 & 1329\\
\addlinespace
DNACorpus2/EsCo & 4641652 & 1593404 & 2.913 & 519 & 115\\
DNACorpus2/GaGa & 148532294 & 46851765 & 3.170 & 39265 & 4702\\
DNACorpus2/ScPo & 10652155 & 3590856 & 2.966 & 1610 & 290\\
DNACorpus2/HaHi & 3890005 & 1306708 & 2.977 & 405 & 97\\
DNACorpus2/HoSa & 189752667 & 57200209 & 3.317 & 50936 & 5833\\
\addlinespace
DNACorpus2/AeCa & 1591049 & 556535 & 2.859 & 125 & 39\\
DNACorpus2/DrMe & 32181429 & 10619042 & 3.031 & 6773 & 999\\
DNACorpus2/BuEb & 18940 & 7893 & 2.400 & 2 & 0\\
DNACorpus2/PlFa & 8986712 & 2895744 & 3.103 & 1254 & 231\\
DNACorpus2/AgPh & 43970 & 17442 & 2.521 & 5 & 2\\
\bottomrule
\end{tabular}}
\end{table}
\hypertarget{using-const-char}{%
\subsection{Using Const Char *}\label{using-const-char}}
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus1/humprtb & 56737 & 21902 & 2.590 & 7 & 2\\
DNACorpus1/humdyst & 38770 & 15300 & 2.534 & 7 & 1\\
DNACorpus1/vaccg & 191737 & 70067 & 2.736 & 15 & 6\\
DNACorpus1/hehcmv & 229354 & 85526 & 2.682 & 15 & 8\\
DNACorpus1/mpomtcg & 186609 & 70254 & 2.656 & 16 & 6\\
\addlinespace
DNACorpus1/humhdab & 58864 & 22699 & 2.593 & 9 & 2\\
DNACorpus1/chmpxx & 121024 & 43516 & 2.781 & 12 & 4\\
DNACorpus1/mtpacga & 100314 & 36862 & 2.721 & 10 & 3\\
DNACorpus1/chntxx & 155844 & 58336 & 2.671 & 14 & 5\\
DNACorpus1/humghcs & 66495 & 25552 & 2.602 & 9 & 2\\
\addlinespace
DNACorpus1/humhbb & 73308 & 28134 & 2.606 & 9 & 2\\
\bottomrule
\end{tabular}}
\end{table}
\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
File.Name & Original.File.Size & Compressed.Size & Compression.Ratio & Compression.Time & Decompression.Time\\
\midrule
DNACorpus2/YeMi & 73689 & 27235 & 2.706 & 9 & 2\\
DNACorpus2/DaRe & 62565020 & 19586457 & 3.194 & 12264 & 1764\\
DNACorpus2/EnIn & 26403087 & 8609993 & 3.067 & 4070 & 708\\
DNACorpus2/HePy & 1667825 & 566972 & 2.942 & 96 & 35\\
DNACorpus2/OrSa & 43262523 & 14148071 & 3.058 & 7627 & 1252\\
\addlinespace
DNACorpus2/EsCo & 4641652 & 1593404 & 2.913 & 348 & 109\\
DNACorpus2/GaGa & 148532294 & 46851765 & 3.170 & 32906 & 4456\\
DNACorpus2/ScPo & 10652155 & 3590856 & 2.966 & 1205 & 265\\
DNACorpus2/HaHi & 3890005 & 1306708 & 2.977 & 271 & 88\\
DNACorpus2/HoSa & 189752667 & 57200209 & 3.317 & 44733 & 5517\\
\addlinespace
DNACorpus2/AeCa & 1591049 & 556535 & 2.859 & 92 & 35\\
DNACorpus2/DrMe & 32181429 & 10619042 & 3.031 & 5266 & 940\\
DNACorpus2/BuEb & 18940 & 7893 & 2.400 & 5 & 0\\
DNACorpus2/PlFa & 8986712 & 2895744 & 3.103 & 879 & 220\\
DNACorpus2/AgPh & 43970 & 17442 & 2.521 & 7 & 1\\
\bottomrule
\end{tabular}}
\end{table}
\hypertarget{trying-different-dictionaries}{%
\section{Trying Different Dictionaries}\label{trying-different-dictionaries}}

\hypertarget{direct-map}{%
\subsection{Direct Map}\label{direct-map}}

\hypertarget{multiple-indexed-dictionaries}{%
\subsection{Multiple Indexed Dictionaries}\label{multiple-indexed-dictionaries}}

\hypertarget{ref-labels}{%
\chapter{Graphics, References, and Labels}\label{ref-labels}}

\hypertarget{figures}{%
\section{Figures}\label{figures}}

If your thesis has a lot of figures, \emph{R Markdown} might behave better for you than that other word processor. One perk is that it will automatically number the figures accordingly in each chapter. You'll also be able to create a label for each figure, add a caption, and then reference the figure in a way similar to what we saw with tables earlier. If you label your figures, you can move the figures around and \emph{R Markdown} will automatically adjust the numbering for you. No need for you to remember! So that you don't have to get too far into LaTeX to do this, a couple \textbf{R} functions have been created for you to assist. You'll see their use below.

In the \textbf{R} chunk below, we will load in a picture stored as \texttt{reed.jpg} in our main directory. We then give it the caption of ``Reed logo'', the label of ``reedlogo'', and specify that this is a figure. Make note of the different \textbf{R} chunk options that are given in the R Markdown file (not shown in the knitted document).
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{include\_graphics}\NormalTok{(}\AttributeTok{path =} \StringTok{"figure/reed.jpg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}

{\centering \includegraphics[width=0.2\linewidth]{figure/reed} 

}

\caption{Reed logo}\label{fig:reedlogo}
\end{figure}
Here is a reference to the Reed logo: Figure \ref{fig:reedlogo}. Note the use of the \texttt{fig:} code here. By naming the \textbf{R} chunk that contains the figure, we can then reference that figure later as done in the first sentence here. We can also specify the caption for the figure via the R chunk option \texttt{fig.cap}.

\clearpage

Below we will investigate how to save the output of an \textbf{R} plot and label it in a way similar to that done above. Recall the \texttt{flights} dataset from Chapter \ref{rmd-basics}. (Note that we've shown a different way to reference a section or chapter here.) We will next explore a bar graph with the mean flight departure delays by airline from Portland for 2014.

Here is a reference to this image: Figure \ref{fig:delaysboxplot}.

A table linking these carrier codes to airline names is available at \url{https://github.com/ismayc/pnwflights14/blob/master/data/airlines.csv}.

\clearpage

Next, we will explore the use of the \texttt{out.extra} chunk option, which can be used to shrink or expand an image loaded from a file by specifying \texttt{"scale=\ "}. Here we use the mathematical graph stored in the ``subdivision.pdf'' file.
\begin{figure}
\includegraphics[scale=0.75]{figure/subdivision} \caption{Subdiv. graph}\label{fig:subd}
\end{figure}
Here is a reference to this image: Figure \ref{fig:subd}. Note that \texttt{echo=FALSE} is specified so that the \textbf{R} code is hidden in the document.

\textbf{More Figure Stuff}

Lastly, we will explore how to rotate and enlarge figures using the \texttt{out.extra} chunk option. (Currently this only works in the PDF version of the book.)
\begin{figure}
\includegraphics[angle=180, scale=1.1]{figure/subdivision} \caption{A Larger Figure, Flipped Upside Down}\label{fig:subd2}
\end{figure}
As another example, here is a reference: Figure \ref{fig:subd2}.

\hypertarget{footnotes-and-endnotes}{%
\section{Footnotes and Endnotes}\label{footnotes-and-endnotes}}

You might want to footnote something. \footnote{footnote text} The footnote will be in a smaller font and placed appropriately. Endnotes work in much the same way. More information can be found about both on the CUS site or feel free to reach out to \href{mailto:data@reed.edu}{\nolinkurl{data@reed.edu}}.

\hypertarget{bibliographies}{%
\section{Bibliographies}\label{bibliographies}}

Of course you will need to cite things, and you will probably accumulate an armful of sources. There are a variety of tools available for creating a bibliography database (stored with the .bib extension). In addition to BibTeX suggested below, you may want to consider using the free and easy-to-use tool called Zotero. The Reed librarians have created Zotero documentation at \url{https://libguides.reed.edu/citation/zotero}. In addition, a tutorial is available from Middlebury College at \url{https://sites.middlebury.edu/zoteromiddlebury/}.

\emph{R Markdown} uses \emph{pandoc} (\url{https://pandoc.org/}) to build its bibliographies. One nice caveat of this is that you won't have to do a second compile to load in references as standard LaTeX requires. To cite references in your thesis (after creating your bibliography database), place the reference name inside square brackets and precede it by the ``at'' symbol. For example, here's a reference to a book about worrying: (Molina \& Borkovec, 1994). This \texttt{Molina1994} entry appears in a file called \texttt{thesis.bib} in the \texttt{bib} folder. This bibliography database file was created by a program called BibTeX. You can call this file something else if you like (look at the YAML header in the main .Rmd file) and, by default, is to placed in the \texttt{bib} folder.

For more information about BibTeX and bibliographies, see our CUS site (\url{https://web.reed.edu/cis/help/latex/index.html})\footnote{Reed~College (2007)}. There are three pages on this topic: \emph{bibtex} (which talks about using BibTeX, at \url{https://web.reed.edu/cis/help/latex/bibtex.html}), \emph{bibtexstyles} (about how to find and use the bibliography style that best suits your needs, at \url{https://web.reed.edu/cis/help/latex/bibtexstyles.html}) and \emph{bibman} (which covers how to make and maintain a bibliography by hand, without BibTeX, at \url{https://web.reed.edu/cis/help/latex/bibman.html}). The last page will not be useful unless you have only a few sources.

If you look at the YAML header at the top of the main .Rmd file you can see that we can specify the style of the bibliography by referencing the appropriate csl file. You can download a variety of different style files at \url{https://www.zotero.org/styles}. Make sure to download the file into the csl folder.

\vfill

\textbf{Tips for Bibliographies}
\begin{itemize}
\tightlist
\item
  Like with thesis formatting, the sooner you start compiling your bibliography for something as large as thesis, the better. Typing in source after source is mind-numbing enough; do you really want to do it for hours on end in late April? Think of it as procrastination.
\item
  The cite key (a citation's label) needs to be unique from the other entries.
\item
  When you have more than one author or editor, you need to separate each author's name by the word ``and'' e.g.~\texttt{Author\ =\ \{Noble,\ Sam\ and\ Youngberg,\ Jessica\},}.
\item
  Bibliographies made using BibTeX (whether manually or using a manager) accept LaTeX markup, so you can italicize and add symbols as necessary.
\item
  To force capitalization in an article title or where all lowercase is generally used, bracket the capital letter in curly braces.
\item
  You can add a Reed Thesis citation\footnote{Noble (2002)} option. The best way to do this is to use the phdthesis type of citation, and use the optional ``type'' field to enter ``Reed thesis'' or ``Undergraduate thesis.''
\end{itemize}
\hypertarget{anything-else}{%
\section{Anything else?}\label{anything-else}}

If you'd like to see examples of other things in this template, please contact the Data @ Reed team (email \href{mailto:data@reed.edu}{\nolinkurl{data@reed.edu}}) with your suggestions. We love to see people using \emph{R Markdown} for their theses, and are happy to help.

\hypertarget{conclusion}{%
\chapter*{Conclusion}\label{conclusion}}
\addcontentsline{toc}{chapter}{Conclusion}

If we don't want Conclusion to have a chapter number next to it, we can add the \texttt{\{-\}} attribute.

\textbf{More info}

And here's some other random info: the first paragraph after a chapter title or section head \emph{shouldn't be} indented, because indents are to tell the reader that you're starting a new paragraph. Since that's obvious after a chapter or section title, proper typesetting doesn't add an indent there.

\appendix

\hypertarget{the-first-appendix}{%
\chapter{The First Appendix}\label{the-first-appendix}}

This first appendix includes all of the R chunks of code that were hidden throughout the document (using the \texttt{include\ =\ FALSE} chunk tag) to help with readibility and/or setup.

\textbf{In the main Rmd file}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This chunk ensures that the thesisdown package is}
\CommentTok{\# installed and loaded. This thesisdown package includes}
\CommentTok{\# the template files for the thesis.}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{require}\NormalTok{(remotes)) \{}
  \ControlFlowTok{if}\NormalTok{ (params}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Install needed packages for \{thesisdown\}}\StringTok{\textasciigrave{}}\NormalTok{) \{}
    \FunctionTok{install.packages}\NormalTok{(}\StringTok{"remotes"}\NormalTok{, }\AttributeTok{repos =} \StringTok{"https://cran.rstudio.com"}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{stop}\NormalTok{(}
      \FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}You need to run install.packages("remotes")",}
\StringTok{            "first in the Console.\textquotesingle{}}\NormalTok{)}
\NormalTok{    )}
\NormalTok{  \}}
\NormalTok{\}}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{require}\NormalTok{(thesisdown)) \{}
  \ControlFlowTok{if}\NormalTok{ (params}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Install needed packages for \{thesisdown\}}\StringTok{\textasciigrave{}}\NormalTok{) \{}
\NormalTok{    remotes}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"ismayc/thesisdown"}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{stop}\NormalTok{(}
      \FunctionTok{paste}\NormalTok{(}
        \StringTok{"You need to run"}\NormalTok{,}
        \StringTok{\textquotesingle{}remotes::install\_github("ismayc/thesisdown")\textquotesingle{}}\NormalTok{,}
        \StringTok{"first in the Console."}
\NormalTok{      )}
\NormalTok{    )}
\NormalTok{  \}}
\NormalTok{\}}
\FunctionTok{library}\NormalTok{(thesisdown)}
\CommentTok{\# Set how wide the R output will go}
\FunctionTok{options}\NormalTok{(}\AttributeTok{width =} \DecValTok{70}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\textbf{In Chapter \ref{ref-labels}:}

\hypertarget{the-second-appendix-for-fun}{%
\chapter{The Second Appendix, for Fun}\label{the-second-appendix-for-fun}}

\backmatter

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\noindent

\setlength{\parindent}{-0.20in}
\begin{verbatim}
Huffman, D. A. (1952). A method for the construction of minimum-redundancy codes. Proceedings of the IRE, 40(9), 1098-1101.
Sayood, K. (2017). Introduction to data compression. Academic Press.
Witten, I. H., Neal, R. M., & Cleary, J. G. (1987). Arithmetic coding for data compression. Communications of the ACM, 30(6), 520-540.
Sayood, K. (2017). Introduction to data compression. Academic Press.
Pratas, Diogo & Pinho, Armando. (2018). A DNA Sequence Corpus for Compression Benchmark. 208-215. 10.1007/978-3-319-98702-6_25.
\end{verbatim}
\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-angel2000}{}}%
Angel, E. (2000). \emph{Interactive computer graphics : A top-down approach with OpenGL}. Boston, MA: Addison Wesley Longman.

\leavevmode\vadjust pre{\hypertarget{ref-angel2001}{}}%
Angel, E. (2001a). \emph{Batch-file computer graphics : A bottom-up approach with QuickTime}. Boston, MA: Wesley Addison Longman.

\leavevmode\vadjust pre{\hypertarget{ref-angel2002a}{}}%
Angel, E. (2001b). \emph{Test second book by angel}. Boston, MA: Wesley Addison Longman.

\leavevmode\vadjust pre{\hypertarget{ref-grumbach}{}}%
Grumbach, S., \& Tahi, F. (1994). {A New Challenge for Compression Algorithms: Genetic Sequences}. \emph{{Information Processing and Management}}, \emph{30}. Retrieved from \url{https://hal.inria.fr/inria-00180949}

\leavevmode\vadjust pre{\hypertarget{ref-Molina1994}{}}%
Molina, S. T., \& Borkovec, T. D. (1994). The {P}enn {S}tate worry questionnaire: Psychometric properties and associated characteristics. In G. C. L. Davey \& F. Tallis (Eds.), \emph{Worrying: Perspectives on theory, assessment and treatment} (pp. 265--283). New York: Wiley.

\leavevmode\vadjust pre{\hypertarget{ref-noble2002}{}}%
Noble, S. G. (2002). \emph{Turning images into simple line-art} (Undergraduate thesis). Reed College.

\leavevmode\vadjust pre{\hypertarget{ref-prataspinho}{}}%
Pratas, D., \& Pinho, A. (2018). A DNA sequence corpus for compression benchmark. In (pp. 208--215). http://doi.org/\href{https://doi.org/10.1007/978-3-319-98702-6_25}{10.1007/978-3-319-98702-6\_25}

\leavevmode\vadjust pre{\hypertarget{ref-reedweb2007}{}}%
Reed~College. (2007). LaTeX your document. Retrieved from \url{https://web.reed.edu/cis/help/LaTeX/index.html}

\end{CSLReferences}

% Index?

\end{document}
