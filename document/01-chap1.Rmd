# Background and Motivations

This thesis deals with some high-level topics and uses language specific to compression research. This chapter gives brief summaries and examples of the relevant topics to be discussed so readers of all experience levels can put our results into context.

## What is information?

  Suppose you had an idea that you wanted to share with another person. Humans have many ways to communicate information; you could send a text message, you could use words, you could use sign language. Regardless of the medium, there is some important idea to get across. Does it matter if the other person gets your message exactly? If someone asks you "Where library?", despite the lack of prepositions, you still understand what they mean. So did that person convey any less information than a person who asks "Where is the library"?
  Clearly, information is fundamental to how humans interact and how they understand the world, but defining it proves difficult. For our purposes, let's assume that information is data with significance that makes it worth preserving and conveying.

Information on computers can take many forms, such as text, audio, and video. This information can travel through many channels including the internet, wires, and screens. To maximize the amount of information that can be transmitted through a channel with a limited capacity, we need to encode the information in a way which minimizes its size, while also preserving its essential features. This process is called compression.
  
## Compression Metrics

### Compression Ratio

Compression Ratio is the measure of size reduction achieved by a compression algorithm. It is typically expressed as a ratio of the size of the original, uncompressed size ($OS$) to the compressed size ($CS$). 

$$CR = \frac{OS}{CS}$$

So a higher compression ratio means a more effective compression algorithm, and means that we were able to store more information in less space, allowing for easier storage and transfer.

### Compression Time

The run time is also an important part of evaluating the effectiveness of a compression algorithm. Run time is typically defined as the length of time a program takes to complete a task. In this case, we are interested in compression time. Sometimes, if time is constrained, you may care less about saving space. For example, suppose you have the option of two compression algorithms, one with a compression ratio of 2.0, and another with a compression ratio of 2.15. If the one with the higher compression ratio takes twice as long as the other, you may opt for a lower compression ratio to save time. 

### Memory Usage

Memory usage is closely tied with runtime when it comes to compression algorithms. Memory is generally the storage a program uses while it is running. So to reduce our run time and make a more effective compression algorithm, we want to be saving only the most important data that our algorithm needs in order to reduce our memory usage. Throughout this thesis, we will assume that most of memory usage is encapsulated in our measurement of compression time.

## Lossy vs. Lossless Compression

### Lossy

Lossy compression is based on the idea that not all information is vital. For instance, when saving a picture on your computer, your computer may save it in the .jpeg format to save space. Jpegs lose some of the information in the original picture and produce an overall lower quality photo, but the general information in the picture is preserved. Another example is MP3 audio files. MP3 compression discards some of the information and sound quality in exchange for a file that takes up less space, which is often favorable for devices with limited storage like MP3 players and cellphones.

### Lossless

Lossless compression is the compression of data with the goal of preserving all the information in the data so that it can be reproduced perfectly on decompression. As a result, lossless compression algorithms usually don't compress as well as their lossy counterparts. Lossless algorithms are important for use cases in which data needs to be wholly recovered, like scientific data, archiving (e.g a .zip folder), and high end audio recording. Examples of lossless compression algorithms are Huffman Encoding and Lempel-Ziv-Welch.

## Classic Compression Algorithms

### Run Length Encoding

Run Length Encoding (RLE) is one of the simplest and most intuitive forms of compression. We can take advantage of redundant runs of characters in a sequence by encoding the number of times each character appears.
  Suppose you want to send the following message 
  
  $$AAGCTTTTTTTTGGGGGCCCT$$
  
We can still get this message across without repeating ourself quite as much. When writing a grocery list, you don't write "egg egg egg egg", you say "4 eggs". RLE uses this same strategy. 

  $$2A1G1C8T5G3C1T$$

Although not as sophisticated as other methods, RLE is effective when used on applications with large runs of repetitive data. For instance, photos that have solid backgrounds, like a logo, can be effectively compressed by RLE.

### Huffman

Huffman Encoding is a lossless compression algorithm that assigns variable length code to certain symbols in the data. The goal is to assign short codes to frequently appearing symbols and longer codes to less frequent symbols.

Suppose we have a message "ACAGGATGGC". We can calculate the frequency of each letter by counting the number of times each letter shows up and dividing by the total number of letters 

```{r, echo=F}
letters <- c('A', 'C', 'T', 'G')
frequencies <- c(0.3, 0.2, 0.1, 0.4)
df =  data.frame(letters, frequencies)

```
Then, we can use the frequencies to build a tree, which will assign short codes for frequent letters and longer code for less frequent letters. The more frequent characters occur higher up in the tree, giving them a shorter length. The less frequent characters occur farther down on the tree. If you follow the branches in Figure \@ref(fig:huffman) down to a letter, it will tell you the code associated with that letter.

\begin{figure}[h]\centering


\tikzset{iv/.style={draw,fill=red!50,circle,minimum size=20pt,inner
sep=0pt,text=black},ev/.style={draw,fill=yellow,rectangle,minimum
size=20pt,inner sep=0pt,text=black}}
\begin{forest}
for tree={where n children={0}{ev}{iv},l+=8mm,
if n=1{edge label={node [midway, left] {0} } }{edge label={node [midway, right] {1} } },}
[
 [G]  
 [
  [A]
  [
	[C]
	[T]
  ]
 ] 
] 
\end{forest}

\caption{Example Huffman tree}
\label{fig:huffman}
\end{figure}

So $G=0$, $A = 10$, $T=111$ and $C=110$. Notice that none of the encodings are prefixes of one another, which makes it unambiguous in decoding.

So our message would be encoded to $1011010001011100110$.


### Arithmetic

Arithmetic encoding is another lossless compression algorithm that uses probability to assign codes to symbols in the message. Unlike Huffman, arithmetic encoding assigns a single code to the whole message, rather than separate codes for each symbol.


Here is a simple example. Say we want to encode a string of characters "ACGGT". Arithmetic Encoding also requires the encoder and decoder know the probabilities of each of the characters that could possibly be in the message. Let's say the probabilities of each symbol in the message are

* $P(A) = a_1 = 2/10$
* $P(C) = a_2 = 2/10$
* $P(G) = a_3 = 4/10$
* $P(T) = a_4 = 2/10$

We want to represent the message as a fractional number between 0 and 1. We will divide the interval [0,1] into sub intervals using the probabilities of each character in the message. That way, each symbol is represented by the sub-interval that corresponds to its probability.

```{r arithmeticencoding, echo = FALSE, fig.cap="Example of arithmetic encoding.", out.width="0.9\\linewidth", fig.align="center"}
include_graphics(path = "figure/arithmeticencoding.png")
```
Since 'A' comes first, we divide [0,1] into [0.0,0.2) since $P(A) = 2/10$. Since 'C' is next, we divide the new fraction of the space [0.0, 0.2) into chunks based on the probabilities of the characters and choose the chunk corresponding to 'C'. Figure \@ref(fig:arithmeticencoding) shows this process through the whole string "ACGGT". We end up with an interval from 0.0688 to 0.06752.

So any number in the interval can be used to represent our message as long as the decoder knows the probabilities that we used to encode it.

### Lempel-Ziv-Welch

Lempel-Ziv-Welch is another lossless compression algorithm. When compressing, LZW builds a dictionary of codewords. A dictionary is a key value system: when you give it a key, it either gives you a value or tells you that the key does not exist. In this case, the keys are strings of characters and the values are codewords, which are numbers meant to represent those strings.

Here is a simple example. Suppose we decide that 'AA' = 2. In other words, any time we see the number 2, we know that it actually means 'AA'. So if we wanted to send a message

$$\text{AACAAC}$$

We could just say

$$\text{2C2C}$$

As long as the person recieving this message understood that 'AA' = 2, they could easily determine what I meant. LZW works in the same way. This rule that we started with, that 'AA' = 2, is essentially a dictionary. It holds keys and values. To make the example more complex, suppose we decide that {'AA' = 1, 'C' = 2}. We could encoding the message "AACAAC" as

$$\text{1212}$$

As you can see, our message is getting shorter. The problem is, how do we decide what elements start in our dictionary? Well, we can start with a small dictionary, and build up a larger dictionary as we go along. Let me explain. Suppose we are still trying to encode "AACAAC". Assume we start with the dictionary {'AA' = 1}. We can scan through the message, looking for instances of 'AA' and replace them. We see "AAC" at the beginning of the string. We can encode this as "1C". Here is our message so far

$$\text{1CAAC}$$

But what if we see the string "AAC" again? Well, when we output "1C", we can add this new string, "AAC", to our dictionary. So our dictionary now looks like {'AA' = 1, 'AAC' = 2}. Notice we just assign the new string whatever number we left off on while creating the dictionary.

Now, as we get to the end of the message, we see "AAC" again. Now that we have a codeword for "AAC", we can just output 2. So our final message looks like

$$\text{1C2}$$

Now the person decoding, when they see "1C", they know that that means "take the string that has codeword 1, add on the character 'C', and add that new string to your dictionary". So they will add 'AAC' = 2 to their dictionary. When they see the following 2, they know that 2 = 'AAC', so they are able to decode the message. In this way, we can build up the dicionary as we encode and decode, and as long as we start with the same starting dictionary, the message will always be preserved.

Here is a more complex example. We may be sending messages with the characters 'A', 'C', 'T', 'G', so we can start by assigning those strings codewords. So our dictionary will start as {'A' = 0, 'C' = 1, 'T' = 2, 'G' = 3}. So in other words, 'A' is synonymous with 0, 'C' is synonymous with 1, and so on. Say we compress to send the message 

$$\text{AAGGAATCC}$$

When we compress, we start at the beginning of the message and scan through. We ask ourselves, "Is 'A' in our dictionary?"

$$\textbf{A} \text{AGGAATCC}$$

Well, we started with 'A' in our dictionary, so we can check in the dictionary and confirm it is there. We then add on the next character in the sequence and ask "Is "AA" in our dictionary?"

$$\textbf{AA} \text{GGAATCC}$$

We have not seen "AA" before, so we should add it to our dictionary. So now our dictionary looks like this {'A' = 0, 'C' = 1, 'T' = 2, 'G' = 3, 'AA' = 4}. Next time we see "AA", we know it is associated with the codeword 4. To indicate this, in our resulting string we will output the code for "A", the part of the string we've seen before, and the character "A".

So the encoded string will look something like

$$\text{0A....}$$

\begin{table}
\begin{tabular}{ | c | c | p{.4\textwidth} | c | }
\hline
\textbf{Step} & \textbf{Input String} & \textbf{Dictionary State} & \textbf{Encoded String} \\
\hline
1 & \textbf{A}AGGAATCC & {A: 0, G: 1, T: 2, C: 3} & - \\
\hline
2 & \textbf{AA}GGAATCC & {A: 0, G: 1, T: 2, C: 3} & 0A \\
\hline
3 & AA\textbf{G}GAATCC & {A: 0, G: 1, T: 2, C: 3, AA: 4} & 0A  \\
\hline
4 & AA\textbf{GG}AATCC & {A: 0, G: 1, T: 2, C: 3, AA: 4} & 0A1G   \\
\hline
5 & AAGG\textbf{A}ATCC & {A: 0, G: 1, T: 2, C: 3, AA: 4, GG: 5} & 0A1G \\
\hline
6 & AAGG\textbf{AA}TCC & {A: 0, G: 1, T: 2, C: 3, AA: 4, GG: 5, GA: 6} & 0A1G  \\
\hline
7 & AAGG\textbf{AAT}CC & {A: 0, G: 1, T: 2, C: 3, AA: 4, GG: 5, GA: 6} & 0A1G4T  \\
\hline
8 & AAGGAAT\textbf{C}C & {A: 0, G: 1, T: 2, C: 3, AA: 4, GG: 5, GA: 6, AAT: 7} & 0A1G4T \\
\hline
9 & AAGGAAT\textbf{CC} & {A: 0, G: 1, T: 2, C: 3, AA: 4, GG: 5, GA: 6, AAT: 7} & 0A1G4T3C \\
\hline
10 & AAGGAATCC & {A: 0, G: 1, T: 2, C: 3, AA: 4, GG: 5, GA: 6, AAT: 7, CC: 8} & 0A1G4T3C \\
\hline
\end{tabular}
\caption{ An example of LZW ran on the input "AAGGAATCC"}
\label{tab:lzwexample}
\end{table}


Table \@ref(tab:lzwexample) illustrates this example fully.

When we are decoding, we start with the same dictionary. We see "0A" and know that that means "Take the string that has codeword 0, add on the character 'A' and add that new string to the dictionary". We would add "AA" to the dictionary and assign it to our next available codeword, 4. Again, while decoding, we are able to build up the same dictionary as was used for encoding, as long as we use the same starting dictionary.
LZW has several convenient properties:

+ When we send this encoding to someone else, we don't need to send a "codebook" (our dictionary). They are able to build it up themselves as they decode. 
+ There only needs to be one run over the data to encode and decode. This means that the run time of the algorithm should increase linearly with the length of the input. 
+ As runs get longer, we will start to see more and more repeating patterns, and replacing them with codewords will become more and more effective.

To decode, we can simply start with the same dictionary. We see codewords followed by one character, so we decode that codeword and add the character to the end. Since the decoder continues to look for codewords, we need some special character at the end of our encoding to let the decoder know when the message is done.

Now that we have laid out how the algorithm works, we can get more specific for our use case. For us, the input is a file on the computer, and the output is also a file (hopefully a smaller one). We read all the characters in the file, encode them, and put them into a new file. Then, when we want to decode, we read the encoded file and output the decoded characters. Again, LZW is lossless, so the original file and the decoded file should be identical.

Here is some example pseudocode

```
LZWEncode(input):

	Dictionary dictionary; // where we store our string => codeword mappings
	dictionary.inititalize; // initialzie the dictionary with single characters

	codeword; // the unique numbers we assign strings
	output; // where we output the encoded characters

	currentBlock = first character of input;
	for every nextCharacter in the input:
		
		// this function returns the longest string we've already seen
		// starting at our current place in the input
		nextLongestRun = findLongestInDict();

		if currentCharacter + nextLongestRun.length > input.length:
			break;
			
		// output the code of the next longest run and next character
		code = dictionary.lookup(nextLongestRun);
		nextCharacter = input[nextLongestRun + 1]
		output(code);
		output(nextCharacter);

		
		dictionary.add(currentBlock + nextCharacter, map it to codeword);

		codeword = codeword + 1;
		input = input + nextLongestRun + 1;


	output(special end of file character);

```

The decoding is much simpler. The only real difference is that we are now mapping codewords to strings, since the encoded string contains codewords.


```
LZWDecode(input):

	Dictionary dictionary; // where we store our codeword => string mappings
	dictionary.inititalize; // initialzie the dictionary with single characters

	codeword; // the unique numbers we assign strings
	result; // where we output the encoded characters

	while we don't see the end of file character:

		codewordFound = input.readCodeword()
		nextCharacter = input.readCharacter()

		sequence = dictionary.lookup(codewordFound) + nextCharacter
		result.output(sequence)

		dictionary.add(sequence = codeword)
		codeword = codeword + 1;

```

This is the basic strategy we will start with for our LZW algorithm. In the next chapter, we will go over parts of the algorithm in depth in C++. Here is a quick summary of terms repeated throughout the next two chapters.

+ `dictionary`: a key-value system. Like a real dictionary holds words and their corresponding definitions, our dictionary holds codewords and their corresponding strings of characters. In C++, this is called a `std::unordered_map` and uses a hash table, but the concept is the same. During this thesis, we will use `std::unordered_map` and Standard Dictionary interchangeably.
+ `codeword`: a number that is assigned to a string in our encoding and decoding. The it is called a `codeword` because it is a code for the string it represents.
+ `run`: the next run of characters in our input that are already in our dictionary. So if we are encoding "ACTG", and "A", "AC", and "ACT" are in the dictionary but "ACTG" is not, we have a run of 3.
+ `EOF`: end of file, the special character that we need to output at the end of the encoding.

## Related work 

Deoxyribonucleic acid (DNA) is the building block of life. In four letters (A, C, G, and T) called nucleotides, DNA holds the genetic information required for reproduction in all living organisms. DNA can be billion of characters long, which can mean gigabytes or terabytes of storage on a computer.
The idea of compressing DNA is not novel, nor is the idea of using LZW for this purpose. DNA compression is a significant research area in the intersection of bioinformatics, computer science, and mathematics.

There have been several attempts to optimize LZW by computer science researchers. One paper made use of multiple indexed dictionaries in order to speed up the compression process [@KeerthyMID]. The concept is simple: rather than a single large dictionary, have multiple dictionaries, one for each possible string length. This allows each of the dictionaries to grow more slowly, allowing accesses to be faster. This paper also used genomic data to gather their metrics and compared their algorithm to other popular DNA compression techniques, which makes it particularly relevant for this thesis.

Another paper used simple parallelization techniques to improve compression speed [@panialok]. Rather than compressing the whole file linearly, the researches broke the file into portions and compressed them with LZW in parallel, which greatly increased the compression speed at the cost of a reduced compression ratio. 

Another paper made use of Chinese Remainder Theorem (CRT) to augment Lempel-Ziv-Welch [@ibrahimgbolagade]. They saw great reduction in compression time without compromising compression ratio, although these results could not be verified. The details of their implementation were not clear from the paper. We tried multiple different methods of utilizing CRT given the pseudocode in their paper, but we were not able to achieve similar results. We reached out to the authors, but we were not able to further our progress on this method and thus it is not used in this thesis.


DNA-specific compression algorithms have also been a growing subsection of computer science for decades. These papers do not focus on LZW, but they do consider some similar methods.

One of the first papers exploring this was published in 1994 [@grumbach]. It proposes an algorithm called `biocompress2`, expanding on a previous paper by the same author. They focus on encoding palindromes in DNA sequences, which allows them to achieve an above average compression ratio, though performance is not evaluated. This paper has been cited by many following papers sparking interest in DNA compression, and the collection of sequences that it uses for algorithm comparison is used in this thesis.

Chen et al. proposed an algorithm called `GenCompress`, which uses approximate matching [@Chen2001ACA]. It matches sequences of nucleotides to sequences already seen in the file, and maps those sequences using various edits to turn one sequence into another. They are able to achieve a great compression ratio with this relative matching method, although their technique is computationally expensive.

In 2007, Cao et al. published a paper detailing another algorithm, `XM`, which uses statistical methods to try and predict the next character while encoding and decoding [@CaoXM]. This method was found to outperform both `biocompress2` and `GenCompress` in terms of compression ratio.

A paper in 2021 uses segmenting and partitioning to create a parallel compression algorithm called `genozip` [@genozip]. This paper also published their code online in a convenient format which allows others to compare and test their implementation. 

As a whole, these papers give us some guidance in terms of where to aim our research. Most of them boast great compression ratios, but their methods can be very computationally intensive in some cases, and thus, slow. We will aim to use previous research on LZW to make a very fast implementation for DNA sequences, then try and use characteristics of the sequences to improve compression ratio. Our hope isn't necessarily to create the best compression ratio out of all these methods, but to make a fast LZW implmentation with a respectable compression ratio. If we are able to make the algorithm very fast, it may be preferable to these other algorithms if the file is very large.
