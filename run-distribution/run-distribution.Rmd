---
title: "Run Distrubution"
author: "Caden Corontzos"
output:
  pdf_document
graphics: yes
urlcolor: blue
---

```{r setup, include=FALSE}
#!/c/R/R-3.2.2/bin/Rscript.exe
# Do not modify this chunk.
knitr::opts_chunk$set(echo = F, message=FALSE, warning = FALSE, fig.align = "center")
library(knitr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(formattable)
```


On each iteration of LZW, the algorithm keeps adding letters to a string until it finds the longest string that it has already seen before. If we know the distribution of the lengths of these strings, we may be able to better optimize our dictionary data structure.

I ran the basic LZW algorithm on the two corpora and counted the length of these runs.

```{r, echo=F}
run_dist_corpus1 = read.csv("run-distribution-DNACorpus1.csv")
run_dist_corpus2 = read.csv("run-distribution-DNACorpus2.csv")
run_dist_corpus1 %>% 
  ggplot(aes(x=Run.Length))+
  geom_histogram()+
  ggtitle("Run Lengths for Corpus 1")
```

A summary for Corpus1. 

```{r}
run_dist_corpus1 %>% 
  summarize(
    average_run_length = mean(Run.Length),
    maximum_run_length = max(Run.Length),
    median_run_length = median(Run.Length),
    sd_run_length = sd(Run.Length)
  )
```


```{r}
run_dist_corpus2 %>% 
  ggplot(aes(x=Run.Length))+
  geom_histogram()+
  ggtitle("Run Lengths for Corpus 2")
```
A summary for corpus 2

```{r}
run_dist_corpus2 %>% 
  summarize(
    average_run_length = mean(Run.Length),
    maximum_run_length = max(Run.Length),
    median_run_length = median(Run.Length),
    sd_run_length = sd(Run.Length)
  )
```

A summary of both corpora.
```{r}
all_corpus_runs = full_join(run_dist_corpus1,run_dist_corpus2)
all_corpus_runs %>% 
  summarize(
    average_run_length = mean(Run.Length),
    maximum_run_length = max(Run.Length),
    median_run_length = median(Run.Length),
    sd_run_length = sd(Run.Length)
  )
```


